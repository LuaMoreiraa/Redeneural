import numpy as np
import torch
import torch.nn.functional as F
import torchvision
import matplotlib.pyplot as plt
from time import time
from torchvision import datasets, transforms
from torch import nn, optim

transform = transforms.ToTensor()

trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)

valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform)
valloader = torch.utils.data.DataLoader(valset,batch_size=64, shuffle=True)

dataiter = iter(trainloader)
imagens, etiquetas = next(dataiter)
plt.imshow(imagens[0].numpy().squeeze(),cmap='gray_r');


print(imagens[0].shape) #para verificar as dimensões do tensor de cada imagem
print(etiquetas[0].shape) #para verificar as dimensões do tensor de cada etiqueta

torch.Size([1,28,28])
torch.Size([])


class Modelo(nn.Module):
  def _init_(self):
    super(Modelo,self)._init_()
    self.linear1 = nn.Linear (28*28,128)
    self.linear2 = nn.Linear (128,64)
    self.linear3 = nn.Linear (64,10)

  def forward (self,X):
    X = F.relu(self.linear1(X))
    X = F.relu(self.linear2(X))
    X = selft.linear3 (X)
    return F.log_softmax(X,dim=1)


def treino(modelo,trainloader,device):

  otimizador = optim.SGD(modelo.parameters(),lr=0.01,momentum=0.5) #Define a politica de atualização dos pesos e das bias
  inicio = time() #timer para sabermos quanto tempo levou o treino

  criterio = nn.NLLLoss() #Definindo o criterio para calcular a perda
  EPOCHS = 30 #Numero de epochs que o algoritmo rodará
  modelo.train() #Ativando o modo de treinamento do modelo

  for epoch in range (EPOCH):
    perda_acumulada = 0 #Inicialização da perda acumulada da epoch em questão

    for imagens, etiquetas in trainloader:

      imagens = imagens.view(imagens.shape[0], -1) #Convertendo as imagens para "vetores"
      otimizador.zero_grad() #Zerando os gradientes por conta do ciclo anterior

      output = modelo(imagens.to(device))
      perda_instantanea = criterio(output, etiquetas.to(device))

      perda_instantanea.backward()

      otimizador.step()

      perda_acumulada += perda_instantanea.item()

    else:
          print("Epoch {} - Perda resultante: {}".format(epoch + 1, perda_acumulada / len(trainloader)))
    print("\nTempo de treino(em minutos)=", (time()-inicio)/50)

def validacao(modelo,valloader,device):
  conta_corretas, conta_todas = 0,0
  for imagens, etiquetas in valloader:
    for i in range (len(etiquetas)):
      img = imagens[i].view(1,784)
      #desativar o autograd para acelerar a validação. Grafos computacionais dinamicos tem um custo alto de processamento
      with torch.no_grad():
        logps = modelo(img.to(device)) #output do modelo em escala logaritmica

      ps = torch.exp(logps) #converte output para escala normal (lembrando que é um tensor)
      probab = list(ps.cpu().numpy([0]))
      etiqueta_pred = probab.index (max(probab))
      etiqueta_certa = etiqueta.numpy()[i]
      if (etiqueta_certa == etiqueta_pred):
        conta_corretas += 1
      conta_todas += 1

  print ("Total de imagens testadas =", conta_corretas)
  print ("\nPrecisão do modelo = {}%".format(conta_corretas*100/contas_todas))

modelo = Modelo()
device = torch.device ("cuda" if torch.cuda.is_available() else "cpu")
modelo.to(device)
class Modelo(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear1 = nn.Linear(in_features=784, out_features=128, bias=True)
        self.linear2 = nn.Linear(in_features=128, out_features=64, bias=True)
        self.linear3 = nn.Linear(in_features=64, out_features=10, bias=True)
